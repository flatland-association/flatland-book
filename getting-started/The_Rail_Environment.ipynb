{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMy8Du_B1qGe"
   },
   "source": [
    "# Using `RailEnv`\r\n",
    "\r\n",
    "In this notebook, we will see how to create, interact with and render railway systems with `RailEnv` the flatland env class.\r\n",
    "\r\n",
    "You can run this document as an interactive notebook in one click:\r\n",
    "\r\n",
    "<!-- [![Open In Binder](https://mybinder.org/static/images/badge_logo.svg)](https://mybinder.org/v2/gh/MasterScrat/getting-started/master?filepath=notebook_1.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MasterScrat/getting-started/blob/master/notebook_1.ipynb) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKOaUC3dc9m_"
   },
   "source": [
    "## Setup\n",
    "1. Install Flatland\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ibjxleKO1qGk",
    "outputId": "721a03e8-243b-4cd6-c970-8cf8158db94a"
   },
   "outputs": [],
   "source": [
    "!pip install -U flatland-rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sVC6olS1qGi"
   },
   "source": [
    "## The Environment\r\n",
    "Let's first go over the main use cases of `RailEnv`, the Flatland environment.\r\n",
    "\r\n",
    "The basic usage of the `RailEnv` environment consists in creating a `RailEnv` object endowed with\r\n",
    "-  a **rail generator**, that generates new rail networks on each reset,\r\n",
    "-  a **line generator**, that generates start and end points for each agent on reset,\r\n",
    "- an **observation builder**, that provides a suitable observation vector to the agents. \r\n",
    "\r\n",
    "For now, let's see how we can create rail networks and use them to train agents.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzYewu331qG7"
   },
   "outputs": [],
   "source": [
    "from flatland.envs.rail_env import RailEnv\r\n",
    "from flatland.envs.rail_generators import sparse_rail_generator\r\n",
    "from flatland.envs.line_generators import sparse_line_generator\r\n",
    "from flatland.envs.observations import GlobalObsForRailEnv\r\n",
    "\r\n",
    "\r\n",
    "rail_generator = sparse_rail_generator(max_num_cities=2)\r\n",
    "\r\n",
    "# Initialize the properties of the environment\r\n",
    "random_env = RailEnv(\r\n",
    "    width=24,\r\n",
    "    height=24,\r\n",
    "    number_of_agents=1,\r\n",
    "    rail_generator=rail_generator,\r\n",
    "    line_generator=sparse_line_generator(),\r\n",
    "    obs_builder_object=GlobalObsForRailEnv()\r\n",
    ")\r\n",
    "\r\n",
    "# Call reset() to initialize the environment\r\n",
    "observation, info = random_env.reset()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the env\r\n",
    "\r\n",
    "You can use the method `RenderTool.render_env()` to render the env in realtime.\r\n",
    "\r\n",
    "For the sake of this tutorial we define a helper function for inline visualization in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from flatland.utils.rendertools import RenderTool\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def render_env(env,wait=True, env_renderer = None):\n",
    "    if env_renderer is None:\n",
    "        env_renderer = RenderTool(env)\n",
    "    env_renderer.render_env()\n",
    "    image = env_renderer.get_image()\n",
    "    pil_image = PIL.Image.fromarray(image)\n",
    "    clear_output(wait=True)\n",
    "    display(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from flatland.utils.rendertools import RenderTool\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_env(random_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "The environment provides very complete observations by default. You typically won't use this object as-is. One of the main objectives of the Flatland challenge is to **find suitable observations** to solve the task at hand.\n",
    "\n",
    "![stock observations](https://i.imgur.com/oo8EIYv.png)\n",
    "\n",
    "By default, the environment provides global observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NgRSpW_Z1qGv",
    "outputId": "ab5b87d2-384a-46c4-ff5e-ad71d87acc71"
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "for agent_handle in random_env.get_agent_handles():\r\n",
    "    print('Observations for agent {}:'.format(agent_handle))\r\n",
    "    agent_obs = observation[agent_handle]\r\n",
    "\r\n",
    "    print('- Transition map\\n{}\\n'.format(np.transpose(agent_obs[0], (2, 0, 1))))\r\n",
    "    print('- Agent position\\n{}\\n'.format(np.transpose(agent_obs[1], (2, 0, 1))))\r\n",
    "    print('- Agent target \\n{}\\n'.format(np.transpose(agent_obs[2], (2, 0, 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent\n",
    "\n",
    "`RailEnv` is targeted at multi-agents experiments. For this purpose, it is derived from RLLib's `MultiAgentEnv` class. You can [read more details about it here](https://ray.readthedocs.io/en/latest/rllib-env.html).\n",
    "\n",
    "The environment is run by supplying the `step` function with a **dictionary** of actions, whose keys are agents’ handles and the corresponding values are the selected actions. This dictionary is passed to the environment which checks the validity of all actions and update the environment state.\n",
    "\n",
    "The environment returns an array of new observations, a reward dictionary for all the agents as well as a flags indicating which agents are done. This information can be used to update the policy of your agent and if `done[‘__all__’] == True` the episode terminates.\n",
    "\n",
    "Let us implement a simple agent that takes a valid random action at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAqre2BE1qHB"
   },
   "outputs": [],
   "source": [
    "class RandomController:\r\n",
    "    def __init__(self, action_size):\r\n",
    "        self.action_size = action_size\r\n",
    "\r\n",
    "    def act(self, observations):\r\n",
    "        actions = dict()\r\n",
    "        for agent_handle, observation in enumerate(observations):\r\n",
    "            action = np.random.randint(self.action_size)\r\n",
    "            actions.update({agent_handle: action})\r\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment provides a openai gym-like interface.\n",
    "\n",
    "The env simulation moves forward with the step() method which takes a dictionary of valid actions and returns the following\n",
    "- observations represeting the state of the env and the **observation generator**\n",
    "- rewards - the score that rates the agent's performance \n",
    "- status of compeletion of tasks for each agent\n",
    "- additional information regarding the status of the env \n",
    "\n",
    "In the example below, we use `env.get_agent_handles()` to enumerate through the handles, and `RailEnvActions.to_char` to get a symbol representing the agent's direction: **B**ackward, **F**orward, **L**eft, **R**ight or **S**top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "P3NEDJVq1qHk",
    "outputId": "8caee0d0-84a0-4b35-c3a5-d128d64c622b"
   },
   "outputs": [],
   "source": [
    "from flatland.envs.rail_env import RailEnvActions\r\n",
    "\r\n",
    "controller = RandomController(random_env.action_space[0])\r\n",
    "observations, info = random_env.reset()\r\n",
    "actions = controller.act(observations)\r\n",
    "\r\n",
    "# Perform a single action per agent\r\n",
    "for (handle, action) in actions.items():\r\n",
    "    print('Agent {} will perform action {} ({})'.format(handle, action, RailEnvActions.to_char(action)))\r\n",
    "    next_obs, all_rewards, dones, info = random_env.step({handle: action})\r\n",
    "\r\n",
    "print('Rewards for each agent: {}'.format(all_rewards))\r\n",
    "print('Done for each agent: {}'.format(dones))\r\n",
    "print('Misc info: {}'.format(info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nGemVk01qHE"
   },
   "outputs": [],
   "source": [
    "def run_episode(env):\n",
    "    env_renderer = RenderTool(env)\r\n",
    "    controller = RandomController(env.action_space[0])\r\n",
    "    observations, info = env.reset()\r\n",
    "\r\n",
    "    score = 0\r\n",
    "    actions = dict()\r\n",
    "\r\n",
    "    for step in range(50):\r\n",
    "\r\n",
    "        actions = controller.act(observations)\r\n",
    "        next_observations, all_rewards, dones, info = env.step(actions)\r\n",
    "        for agent_handle in env.get_agent_handles():\r\n",
    "            score += all_rewards[agent_handle]\r\n",
    "\r\n",
    "        , env_renderer=env_rendererrender_env(env)\r\n",
    "        print('Timestep {}, total score = {}'.format(step, score))\r\n",
    "\r\n",
    "        if dones['__all__']:\r\n",
    "            print('All done!')\r\n",
    "            return\r\n",
    "\r\n",
    "    print(\"Episode didn't finish after 50 timesteps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an episode in the random environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "zKynbq-r1qHG",
    "outputId": "5bb2abb9-0400-45d5-c546-0b48208392a1"
   },
   "outputs": [],
   "source": [
    "run_episode(random_env)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TKOaUC3dc9m_",
    "1sVC6olS1qGi",
    "FembDogv1qHK"
   ],
   "name": "1. The Rail Environment",
   "provenance": []
  },
  "interpreter": {
   "hash": "ba2c7c47ad9c9f3786a780db1b35afc3c43377b2aa6217e515650f75da49aaac"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
