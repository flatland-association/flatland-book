{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4edcdfc8",
   "metadata": {},
   "source": [
    "# Sequential Agent\n",
    "\n",
    "In this notebook implements a simple greedy agent that moves in the direction of the nearest destination based on the `TreeObsForRailEnv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819fb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from flatland.envs.observations import TreeObsForRailEnv\n",
    "from flatland.envs.rail_env import RailEnv\n",
    "from flatland.envs.rail_generators import sparse_rail_generator\n",
    "from flatland.envs.line_generators import sparse_line_generator\n",
    "from flatland.envs.predictions import ShortestPathPredictorForRailEnv\n",
    "from flatland.utils.rendertools import RenderTool\n",
    "from IPython.display import clear_output\n",
    "import PIL\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_env(env,wait=True, env_renderer = None):\n",
    "    if env_renderer is None:\n",
    "        env_renderer = RenderTool(env)\n",
    "    env_renderer.render_env()\n",
    "\n",
    "    image = env_renderer.get_image()\n",
    "    pil_image = PIL.Image.fromarray(image)\n",
    "    clear_output(wait=True)\n",
    "    display(pil_image)\n",
    "\n",
    "def min_gt(seq, val):\n",
    "    \"\"\"\n",
    "    Return smallest item in seq for which item > val applies.\n",
    "    None is returned if seq was empty or all items in seq were >= val.\n",
    "    \"\"\"\n",
    "    min = np.inf\n",
    "    idx = len(seq) - 1\n",
    "    while idx >= 0:\n",
    "        if seq[idx] >= val and seq[idx] < min:\n",
    "            min = seq[idx]\n",
    "        idx -= 1\n",
    "    return min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6c8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrderedAgent:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.action_size = 5\n",
    "\n",
    "    def act(self, state, eps=0):\n",
    "        \"\"\"\n",
    "        :param state: input is the observation of the agent\n",
    "        :return: returns an action\n",
    "        \"\"\"\n",
    "        distance = []\n",
    "        for direction in TreeObsForRailEnv.tree_explored_actions_char:\n",
    "            try:\n",
    "                distance.append(state.childs[direction].dist_min_to_target)\n",
    "            except:\n",
    "                distance.append(np.inf)\n",
    "        distance = np.array(distance)\n",
    "        min_dist = min_gt(distance, 0)\n",
    "        min_direction = np.where(distance == min_dist)\n",
    "        if len(min_direction[0]) > 1:\n",
    "            return min_direction[0][-1] + 1\n",
    "        return min_direction[0][0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4618b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "x_dim = 30  # np.random.randint(8, 20)\n",
    "y_dim = 30  # np.random.randint(8, 20)\n",
    "n_agents = 3  # np.random.randint(3, 8)\n",
    "n_goals = n_agents + np.random.randint(0, 3)\n",
    "min_dist = int(0.75 * min(x_dim, y_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d55204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RailEnv(width=x_dim,\n",
    "              height=y_dim,\n",
    "              rail_generator=sparse_rail_generator(),\n",
    "              line_generator=sparse_line_generator(),\n",
    "              obs_builder_object=TreeObsForRailEnv(max_depth=1,\n",
    "              predictor=ShortestPathPredictorForRailEnv()),\n",
    "              number_of_agents=n_agents)\n",
    "env.reset()\n",
    "render_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de287d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(env, agent, render = True):\n",
    "    \n",
    "    env_renderer = RenderTool(env)\n",
    "    max_steps = 100 * (env.height + env.width)-1\n",
    "    action_dict = dict()\n",
    "    # Reset environment\n",
    "    obs, info = env.reset(regenerate_rail = False,regenerate_schedule = False)\n",
    "    done = env.dones\n",
    "    env_renderer.reset()\n",
    "    frame_step = 0\n",
    "    score = 0\n",
    "    # Run episode\n",
    "    for step in range(max_steps):\n",
    "\n",
    "        # Action\n",
    "        acting_agent = 0\n",
    "        for a in range(env.get_num_agents()):\n",
    "            if done[a]:\n",
    "                acting_agent += 1\n",
    "            if a == acting_agent:\n",
    "                action = agent.act(obs[a])\n",
    "            else:\n",
    "                action = 4\n",
    "            action_dict.update({a: action})\n",
    "        # Environment step\n",
    "\n",
    "        obs, all_rewards, done, _ = env.step(action_dict)\n",
    "        for agent_handle in env.get_agent_handles():\n",
    "            score += all_rewards[agent_handle]\n",
    "        print('Timestep {}, total score = {}'.format(step, score))\n",
    "\n",
    "\n",
    "        if done['__all__']:\n",
    "            print('All done')\n",
    "            break\n",
    "\n",
    "        # Render\n",
    "        if render:\n",
    "            render_env(env, env_renderer=env_renderer)\n",
    "        else:\n",
    "            clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b202aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_episode(env,OrderedAgent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ebcda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomController:\n",
    "    def __init__(self, action_size):\n",
    "        self.action_size = action_size\n",
    "\n",
    "    def act(self, observations):\n",
    "        actions = dict()\n",
    "        return np.random.randint(self.action_size)\n",
    "\n",
    "random_agent = RandomController(5)\n",
    "run_episode(env,random_agent,False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b033d24faa74254dceab33f5204a8503e2d8016b6a9710319f857f6c85b13d4b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
