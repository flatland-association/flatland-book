{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac66f3b-6b10-4d24-8095-a679295acf7f",
   "metadata": {},
   "source": [
    "Policy Evaluation and Trajectories\n",
    "==================================\n",
    "\n",
    "We use the terms from [arc42](https://docs.arc42.org/section-7/) for the different views."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f13c5-8619-4fb6-9b66-c484e5086575",
   "metadata": {},
   "source": [
    "Building Block View Trajectory Generation and Evaluation\n",
    "--------------------------------------------------------\n",
    "\n",
    "This is a conceptual view and reflects the target state of the implementation. In Flatland implementation, we currently do not yet distinguish between configuration and state, they go together in `RailEnvPersister` and a trajectory currently consists of full snapshots.\n",
    "\n",
    "```{mermaid}\n",
    "classDiagram\n",
    "    class Runner {\n",
    "        Trajectory: +generate_trajectory_from_policy(Policy policy, ObservationBuilder obs_builder, int snapshot_interval)$ Trajectory\n",
    "    }\n",
    "    \n",
    "    class Evaluator {\n",
    "        Trajectory: +evaluate(Trajectory trajectory)\n",
    "    }\n",
    "    \n",
    "    class Trajectory {\n",
    "        Trajectory: +Path data_dir\n",
    "        Trajectory: +UUID ep_id\n",
    "        Trajectory: +run(int from_step, int to_step=-1)\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    class EnvSnapshot {\n",
    "        EnvSnapshot: +Path data_dir\n",
    "        Trajectory: +UUID ep_id\n",
    "    }\n",
    "\n",
    "    class EnvConfiguration\n",
    "    EnvConfiguration: +int max_episode_steps\n",
    "    EnvConfiguration: +int height\n",
    "    EnvConfiguration: +int width\n",
    "    EnvConfiguration: +Rewards reward_function\n",
    "    EnvConfiguration: +MalGen\n",
    "    EnvConfiguration: +RailGen etc. reset\n",
    "\n",
    "    class EnvState {\n",
    "        EnvState: +Grid rail\n",
    "    }\n",
    "\n",
    "    \n",
    "        class EnvConfiguration\n",
    "\n",
    "        class EnvState\n",
    "\n",
    "        class EnvSnapshot\n",
    "        \n",
    "        class EnvActions\n",
    "\n",
    "        class EnvRewards\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    EnvSnapshot --> \"1\" EnvConfiguration\n",
    "    EnvSnapshot --> \"1\" EnvState\n",
    "    Trajectory --> \"1\" EnvConfiguration\n",
    "    Trajectory --> \"1..*\" EnvState\n",
    "    Trajectory --> \"1..*\" EnvActions\n",
    "    Trajectory --> \"1..*\" EnvRewards\n",
    "\n",
    "    class Policy\n",
    "    Policy: act(int handle, Observation observation)\n",
    "\n",
    "    class ObservationBuilder\n",
    "    ObservationBuilder: get()\n",
    "    ObservationBuilder: get_many()\n",
    "\n",
    "    class Submission\n",
    "    Submission --> \"1\" Policy\n",
    "    Submission --> ObservationBuilder\n",
    "```\n",
    "\n",
    "Remarks:\n",
    "\n",
    "* Trajectory needs not start at step 0\n",
    "* Trajectory needs not contain state for every step - however, when starting the trajectory from an intermediate step, the snapshot must exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9270625-2354-48e8-9151-32f7779b4a3e",
   "metadata": {},
   "source": [
    "Runtime View Trajectory Generation\n",
    "--------------------------------\n",
    "\n",
    "```{mermaid}\n",
    "flowchart TD\n",
    "    subgraph PolicyRunner.create_from_policy\n",
    "        start((\"&nbsp;\")) -->|data_dir| D0\n",
    "        D0(RailEnvPersister.load_new) -->|env| E{env done?}\n",
    "        E -->|no:<br/>observations| G{Agent loop:<br/> more agents?}\n",
    "        G --->|observation| G1(policy.act)\n",
    "        G1 -->|action| G\n",
    "        G -->|no:<br/> actions| F3(env.step)\n",
    "        F3 -->|observations,rewards,info| E\n",
    "        E -->|yes:<br/> rewards| H(((\"&nbsp;\")))\n",
    "    end\n",
    "\n",
    "    style Policy fill: #ffe, stroke: #333, stroke-width: 1px, color: black\n",
    "    style G1 fill: #ffe, stroke: #333, stroke-width: 1px, color: black\n",
    "    style Env fill: #fcc, stroke: #333, stroke-width: 1px, color: black\n",
    "    style F3 fill: #fcc, stroke: #333, stroke-width: 1px, color: black\n",
    "    subgraph legend\n",
    "        Env(Environment)\n",
    "        Policy(Policy)\n",
    "        Trajectory(Trajectory)\n",
    "    end\n",
    "\n",
    "    PolicyRunner.create_from_policy~~~legend\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cefc200-fbb1-45f9-8fc1-c1237ea757b2",
   "metadata": {},
   "source": [
    "Trajectory Generation and Evaluation\n",
    "------------------------------------\n",
    "\n",
    "Create a trajectory from a random policy and inspect the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54dc3fa-0ad7-45c4-b177-42bd0fceb999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional\n",
    "\n",
    "from flatland.env_generation.env_generator import env_generator\n",
    "from flatland.core.policy import Policy\n",
    "from flatland.trajectories.policy_runner import PolicyRunner\n",
    "from flatland.utils.seeding import np_random, random_state_to_hashablestate\n",
    "from flatland.evaluators.trajectory_evaluator import TrajectoryEvaluator, evaluate_trajectory\n",
    "from flatland.trajectories.trajectories import Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56103b1e-2a8d-4e77-af02-4a35cb941fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPolicy(Policy):\n",
    "    def __init__(self, action_size: int = 5, seed=42):\n",
    "        super(RandomPolicy, self).__init__()\n",
    "        self.action_size = action_size\n",
    "        self.np_random, _ = np_random(seed=seed)\n",
    "\n",
    "    def act(self, observation: Any, **kwargs):\n",
    "        return self.np_random.choice(self.action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82754d72-7609-4bf6-bc70-94fa21d7485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    data_dir = Path(tmpdirname)\n",
    "    env, _, _ = env_generator(seed=44)\n",
    "    trajectory = PolicyRunner.create_from_policy(policy=RandomPolicy(), env=env, data_dir=data_dir, snapshot_interval=15, tqdm_kwargs={\"disable\": True})\n",
    "    # np_random in loaded episode is same as if it comes directly from env_generator incl. reset()!\n",
    "    env = trajectory.load_env()\n",
    "    # we need to seed explictly to have the same env re-generated!\n",
    "    gen, _, _ = env_generator(seed=44)\n",
    "    assert random_state_to_hashablestate(env.np_random) == random_state_to_hashablestate(gen.np_random)\n",
    "\n",
    "    \n",
    "    # inspect output\n",
    "    for p in sorted(data_dir.rglob(\"**/*\")):\n",
    "        print(p)\n",
    "\n",
    "    # inspect the actions taken by the policy\n",
    "    print(trajectory._read_actions())\n",
    "\n",
    "    # verify steps 5 to 15 - we can start at 5 as there is a snapshot for step 5.\n",
    "    TrajectoryEvaluator(trajectory).evaluate(start_step=15,end_step=25, tqdm_kwargs={\"disable\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445884b-893f-46dd-a911-580ae730b53c",
   "metadata": {},
   "source": [
    "### List of `Policy` implementations\n",
    "* `tests.trajectories.test_trajectories.RandomPolicy`\n",
    "* `flatland.envs.rail_env_policies.ShortestPathPolicy`\n",
    "* `flatland_baselines.deadlock_avoidance_heuristic.policy.deadlock_avoidance_policy.DeadLockAvoidancePolicy` (see [flatland-baselines](https://github.com/flatland-association/flatland-baselines/blob/main/flatland_baselines/deadlock_avoidance_heuristic/policy/deadlock_avoidance_policy.py))\n",
    "* `flatland/ml/ray/wrappers.ray_policy_wrapper` and `flatland/ml/ray/wrappers.ray_checkpoint_policy_wrapper` for wrapping RLlib RLModules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d3ec7-4c15-493e-8d59-c187b4a4338b",
   "metadata": {},
   "source": [
    "Flatland Callbacks\n",
    "------------------\n",
    "Flatland callbacks can be used for custom metrics and custom postprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46277d-8742-45ac-9282-c9c061bf99ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from flatland.envs.rail_env import RailEnv\n",
    "from flatland.callbacks.callbacks import FlatlandCallbacks, make_multi_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eca28b-ccb7-40b3-958f-2d62dfe51406",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines, _ = inspect.getsourcelines(FlatlandCallbacks)\n",
    "print(\"\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465e9fb-0704-4d5d-b774-a335ea58a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyCallbacks(FlatlandCallbacks):\n",
    "    def on_episode_step(\n",
    "        self,\n",
    "        *,\n",
    "        env: Optional[RailEnv] = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        if (env._elapsed_steps - 1) % 10 == 0:\n",
    "            print(f\"step{env._elapsed_steps - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb570663-dbb2-44e7-9c07-4f9e37356faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    data_dir = Path(tmpdirname)\n",
    "    trajectory = PolicyRunner.create_from_policy(policy=RandomPolicy(), env=env_generator()[0], data_dir=data_dir, snapshot_interval=15, tqdm_kwargs={\"disable\": True})\n",
    "    TrajectoryEvaluator(trajectory, callbacks=make_multi_callbacks(DummyCallbacks())).evaluate(tqdm_kwargs={\"disable\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab234b-f305-42fc-be9d-c979daf20ae5",
   "metadata": {},
   "source": [
    "### List of FlatlandCallbacks\n",
    "* `flatland.callbacks.generate_movie_callbacks.GenerateMovieCallbacks`\n",
    "* `flatland.integrations.interactiveai/interactiveai.FlatlandInteractiveAICallbacks`\n",
    "* `flatland.trajectories.trajectory_snapshot_callbacks.TrajectorySnapshotCallbacks`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
